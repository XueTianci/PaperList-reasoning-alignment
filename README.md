# Paper List for Reasoning and Alignment
Record the interesting papers I read. Because I just started recording recently, the paper list may miss many remarkable papers from the past few years.
## Contents

- [Paper List]
  - [Papers for Reasoning](#Reasoning)
  - [Papers for Alignment](#Alignment)
  - [Papers for Agent](#Agent)
  - [Papers for Code](#Code)
 
## Reasoning

1. **Chain of Thought Prompting Elicits Reasoning in Large Language Models**

   *Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, Denny Zhou*. [[pdf](https://arxiv.org/pdf/2201.11903v6.pdf)], 2022.1.28.

2. **Self-Consistency Improves Chain of Thought Reasoning in Language Models**

   *Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou*. [[pdf](https://arxiv.org/pdf/2203.11171.pdf)], 2022.3.21.

3. **Least-to-Most Prompting Enables Complex Reasoning in Large Language Models**

   *Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, Ed Chi*. [[pdf](https://arxiv.org/pdf/2205.10625.pdf)], 2022.5.21.

4. **Self-Refine: Iterative Refinement with Self-Feedback**

   *Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, Sean Welleck, Amir Yazdanbakhsh, Peter Clark*. [[pdf](https://arxiv.org/pdf/2303.17651.pdf)], 2023.3.30.

5. **RCOT: Detecting and Rectifying Factual Inconsistency in Reasoning by Reversing Chain-of-Thought**

   *Tianci Xue, Ziqi Wang, Zhenhailong Wang, Chi Han, Pengfei Yu, Heng Ji*. [[pdf](https://arxiv.org/pdf/2305.11499.pdf)], 2023.5.19.
   
6. **Let's Verify Step by Step**

   *Hunter Lightman, Vineet Kosaraju, Yura Burda, Harri Edwards, Bowen Baker, Teddy Lee, Jan Leike, John Schulman, Ilya Sutskever, Karl Cobbe*. [[pdf](https://arxiv.org/pdf/2305.20050.pdf)], 2023.5.31.

7. **Reinforced Self-Training (ReST) for Language Modeling**

   *Caglar Gulcehre, Tom Le Paine, Srivatsan Srinivasan, Ksenia Konyushkova, Lotte Weerts, Abhishek Sharma, Aditya Siddhant, Alex Ahern, Miaosen Wang, Chenjie Gu, Wolfgang Macherey, Arnaud Doucet, Orhan Firat, Nando de Freitas*. [[pdf](https://arxiv.org/pdf/2308.08998.pdf)], 2023.8.17.

8. **WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct**

   *Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, Dongmei Zhang*. [[pdf](https://arxiv.org/pdf/2308.09583.pdf)], 2023.8.18.

9. **MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models**
    *Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T. Kwok, Zhenguo Li, Adrian Weller, Weiyang Liu*. [[pdf](https://arxiv.org/pdf/2309.12284.pdf)], 2023.9.21.

10. **Large Language Models Cannot Self-Correct Reasoning Yet**

    *Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song, Denny Zhou*. [[pdf](https://arxiv.org/pdf/2310.01798.pdf)], 2023.10.3.

11. **Query and Response Augmentation Cannot Help Out-of-domain Math Reasoning Generalization**

    *Chengpeng Li, Zheng Yuan, Hongyi Yuan, Guanting Dong, Keming Lu, Jiancan Wu, Chuanqi Tan, Xiang Wang, Chang Zhou*. [[pdf](https://arxiv.org/pdf/2310.05506.pdf)], 2023.10.9.

12. **Let's Reinforce Step by Step**

    *Sarah Pan, Vladislav Lialin, Sherin Muckatira, Anna Rumshisky*. [[pdf](https://arxiv.org/pdf/2311.05821.pdf)], 2023.11.10.
    
13. **What Makes Chain-of-Thought Prompting Effective? A Counterfactual Study**

    *Aman Madaan, Katherine Hermann, Amir Yazdanbakhsh*. [[pdf](https://aclanthology.org/2023.findings-emnlp.101.pdf)], 2023.12.1.

14. **Math-Shepherd: A Label-Free Step-by-Step Verifier for LLMs in Mathematical Reasoning**

    *Peiyi Wang, Lei Li, Zhihong Shao, R.X. Xu, Damai Dai, Yifei Li, Deli Chen, Y.Wu, Zhifang Sui*. [[pdf](https://arxiv.org/pdf/2312.08935.pdf)], 2023.12.28.

15. **Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding**

    *Zilong Wang, Hao Zhang, Chun-Liang Li, Julian Martin Eisenschlos, Vincent Perot, Zifeng Wang, Lesly Miculicich, Yasuhisa Fujii, Jingbo Shang, Chen-Yu Lee, Tomas Pfister*. [[pdf](https://arxiv.org/pdf/2401.04398.pdf)], 2024.1.9.

16. **The Impact of Reasoning Step Length on Large Language Models**

    *Mingyu Jin, Qinkai Yu, Dong shu, Haiyan Zhao, Wenyue Hua, Yanda Meng, Yongfeng Zhang, Mengnan Du*. [[pdf](https://arxiv.org/pdf/2401.04925.pdf)], 2023.1.10.

17. **The Unreasonable Effectiveness of Easy Training Data for Hard Tasks**

    *Peter Hase, Mohit Bansal, Peter Clark, Sarah Wiegreffe*. [[pdf](https://arxiv.org/pdf/2401.06751.pdf)], 2023.1.12.

## Alignment

1. **Chain of Hindsight Aligns Language Models with Feedback**

   *Hao Liu, Carmelo Sferrazza, Pieter Abbeel*. [[pdf](https://arxiv.org/pdf/2302.02676.pdf)], 2023.2.6.

2. **Direct Preference Optimization: Your Language Model is Secretly a Reward Model**

   *Bill Yuchen Lin, Abhilasha Ravichander, Ximing Lu, Nouha Dziri, Melanie Sclar, Khyathi Chandu, Chandra Bhagavatula, Yejin Choi*. [[pdf](https://arxiv.org/pdf/2305.18290.pdf)], 2023.3.29.

3. **Exploring the Relationship between In-Context Learning and Instruction Tuning**

   *Hanyu Duan, Yixuan Tang, Yi Yang, Ahmed Abbasi, Kar Yan Tam*. [[pdf](https://arxiv.org/pdf/2311.10367.pdf)], 2023.11.17.

4. **The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning**

   *Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, Chelsea Finn*. [[pdf](https://arxiv.org/pdf/2312.01552.pdf)], 2023.12.4.

5. **Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision**

   *Collin Burns, Pavel Izmailov, Jan Hendrik Kirchner, Bowen Baker, Leo Gao, Leopold Aschenbrenner, Yining Chen, Adrien Ecoffet, Manas Joglekar, Jan Leike, Ilya Sutskever, Jeff Wu*. [[pdf](https://arxiv.org/pdf/2312.09390.pdf)], 2023.12.14.

6. **One Shot Learning as Instruction Data Prospector for Large Language Models**

   *Yunshui Li, Binyuan Hui, Xiaobo Xia, Jiaxi Yang, Min Yang, Lei Zhang, Shuzheng Si, Junhao Liu, Tongliang Liu, Fei Huang, Yongbin Li*. [[pdf](https://arxiv.org/pdf/2312.10302.pdf)], 2023.12.16.
   
7. **Policy Optimization in RLHF: The Impact of Out-of-preference Data**

   *Ziniu Li, Tian Xu, Yang Yu*. [[pdf](https://arxiv.org/pdf/2312.10584.pdf)], 2023.12.17.

8. **What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning**

   *Wei Liu, Weihao Zeng, Keqing He, Yong Jiang, Junxian He*. [[pdf](https://arxiv.org/pdf/2312.15685.pdf)], 2023.12.25.

## Agent

1. **AUTOACT: Automatic Agent Learning from Scratch via Self-Planning**

   *Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, Huajun Chen*. [[pdf](https://arxiv.org/pdf/2401.05268.pdf)], 2023.1.10.

## Code

1. **Leveraging Print Debugging to Improve Code Generation in Large Language Models**

   *Xueyu Hu, Kun Kuang, Jiankai Sun, Hongxia Yang, Fei Wu*. [[pdf](https://arxiv.org/pdf/2401.05319.pdf)], 2023.1.10.

## Other

1. **DoLa: Decoding by Contrasting Layers Improves Factuality in Large Language Models**

   *Yung-Sung Chuang, Yujia Xie, Hongyin Luo, Yoon Kim, James Glass, Pengcheng He*. [[pdf](https://arxiv.org/pdf/2401.02954.pdf)], 2023.9.1.
   
2. **An In-depth Look at Gemini's Language Abilities**

   *Syeda Nahida Akter, Zichun Yu, Aashiq Muhamed, Tianyue Ou, Alex Bäuerle, Ángel Alexander Cabrera, Krish Dholakia, Chenyan Xiong, Graham Neubig*. [[pdf](https://arxiv.org/pdf/2312.11444.pdf)], 2023.12.18.

3. **LLaMA Pro: Progressive LLaMA with Block Expansion**

   *Chengyue Wu, Yukang Gan, Yixiao Ge, Zeyu Lu, Jiahao Wang, Ye Feng, Ping Luo, Ying Shan*. [[pdf](https://arxiv.org/pdf/2401.02415.pdf)], 2023.1.4.

4. **DeepSeek LLM: Scaling Open-Source Language Models with Longtermism**

   *Xiao Bi, Deli Chen, Guanting Chen, Shanhuang Chen, Damai Dai, Chengqi Deng, Honghui Ding, et al.*. [[pdf](https://arxiv.org/pdf/2401.02954.pdf)], 2023.1.5.

5. **Mixtral of Experts**

   *Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary, et al.*. [[pdf](https://arxiv.org/pdf/2401.04088.pdf)], 2023.1.8.



## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=XueTianci/PaperList-reasoning-alignment&type=Date)](https://star-history.com/#XueTianci/PaperList-reasoning-alignment&Date)






